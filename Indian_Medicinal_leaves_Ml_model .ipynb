{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c2c2d-3a85-450e-b3d2-a879b92cad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ce129-2905-4867-b295-af29079b9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1899e-471a-49ec-a80d-bffa129e5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#dataset path setting \n",
    "dataset_path = os.listdir('C://Users//adity//OneDrive//Desktop//dataset')\n",
    "print(dataset_path)\n",
    "print (\"types of classes labels found: \",len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33955955-ae93-4d16-b34e-edf878a96245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to collect all data in single list \n",
    "class_labels =[]\n",
    "\n",
    "for item in dataset_path:\n",
    "    all_classes = os.listdir('C://Users//adity//OneDrive//Desktop//dataset' + '/' +item)\n",
    "    #print(item,len(all_classes))\n",
    "    for room in all_classes:\n",
    "        class_labels.append((item, str('C://Users//adity//OneDrive//Desktop//dataset' + '/' +item) + '/' + room))\n",
    "print (class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26faf8-4ebf-4b3d-a714-46dff2bf1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe \n",
    "\n",
    "df = pd.DataFrame(data=class_labels, columns = ['Labels','image'])\n",
    "print (df.head())\n",
    "print (df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e35e6-3ea9-41f4-bc64-03bde8efdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying data with labels\n",
    "print (\"total number of images in the datset: \", len(df))\n",
    "label_count = df['Labels'].value_counts()\n",
    "print (label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1cca1-50e3-4158-954e-f9187c561a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5871ee-268f-46b4-9225-7bef6531aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing data since Efficient NetB0 requires 224dpi as resolution\n",
    "\n",
    "path = 'C://Users//adity//OneDrive//Desktop//dataset//'\n",
    "dataset_path = os.listdir('C://Users//adity//OneDrive//Desktop//dataset')\n",
    "\n",
    "im_size = 224\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in dataset_path:\n",
    "    data_path = path + str(i)\n",
    "    filenames = [i for i in os.listdir(data_path)]\n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + '//' + f)\n",
    "        new_img = cv2.resize(img,(im_size,im_size))\n",
    "        images.append(new_img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785e29d-d025-4c6e-9977-6b32d62de6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#craeting numpy array of images \n",
    "images = np.array(images)\n",
    "\n",
    "images = images.astype('float32')/255.0        #array must be in 0 to 1 value\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f87288-f3a1-4f82-a051-55d3cf521561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder: to encode labels in numbers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "y = df['Labels'].values\n",
    "print (y)\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "y = y_labelencoder.fit_transform(y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f9b4c-bfbb-4b77-8f58-d913f66403f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder: to create vectors of labels\n",
    "y = y.reshape(-1,1)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('my_ohe',OneHotEncoder(),[0])],remainder='passthrough')\n",
    "Y= ct.fit_transform(y)\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8375f-1193-4462-9bf1-c0a842b5d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train data and test data\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images,Y = shuffle (images, Y , random_state = 1)\n",
    "train_x, test_x, train_y, test_y = train_test_split (images, Y, test_size = 0.05, random_state = 42)\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657cafd-6892-4dab-bfa6-daeae866df9a",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596ebb3-b0fb-415e-afad-823d0b4456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoting EfficientNetB0\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "inputs = layers.Input (shape= (IMG_SIZE,IMG_SIZE,3))\n",
    "\n",
    "#using without transfer learning. Since, it is custom model. so, weights = None\n",
    "outputs= EfficientNetB0(include_top = True, weights = None, classes= NUM_CLASSES)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f95dd-101a-4a0f-a623-802992f9e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Model (inputs,outputs)\n",
    "opt = keras.optimizers.Adam(learning_rate =0.01)\n",
    "model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()\n",
    "hist = model.fit (train_x, train_y, epochs = 12 ,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a7d76-8c62-4fec-84f5-fd5f28aaec14",
   "metadata": {},
   "source": [
    "Plotting the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7f28b-bf62-4b6e-9e24-e7d77ec1b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_hist(hist):\n",
    "    plt.plot (hist.history[\"accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend([\"train\", \"validation\"], loc = \"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb977ec-d69a-41ed-9ddb-94738175fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(test_x, test_y)\n",
    "print (\"Loss=\"+str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str (preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8ab1e-e405-4499-aaf0-df28c8d4a847",
   "metadata": {},
   "source": [
    "Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd55c0d-0f06-468a-a5b5-a8bfe362ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread, imshow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "\n",
    "img_path = \"C:/Users/adity/OneDrive/Desktop/amla1.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (224,224))\n",
    "\n",
    "x = np.expand_dims(img,axis=0)\n",
    "x = preprocess_input (x)\n",
    "\n",
    "print (\"input image shape: \", x.shape)\n",
    "\n",
    "my_img = imread(img_path)\n",
    "imshow (my_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a1042-13a7-4a0f-81d4-75c384b7fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(x)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b26cc-253c-453e-bcd1-37ec5e70a929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670f4cc-75e4-4403-b787-a2b04e21604d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
